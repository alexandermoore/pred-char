{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.models import Model\n",
    "from keras.backend import clear_session\n",
    "from keras.optimizers import Adam\n",
    "from functions import *\n",
    "import string\n",
    "import random\n",
    "VALID_CHARS = set([x for x in (string.ascii_lowercase + \"0123456789\" + '.!?,-\" ')])\n",
    "REPLACE_CHARS = {\n",
    "    \";\": '.',\n",
    "    '\\n': ' '\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_text_len = 1000000\n",
    "norm_text = normalize_text(load_text(\"obama.txt\"), VALID_CHARS, REPLACE_CHARS)[:truncate_text_len]\n",
    "split_idx = int(len(norm_text) * 0.80)\n",
    "norm_text_train = norm_text[:split_idx]\n",
    "norm_text_val = norm_text[split_idx:]\n",
    "vocab, inv_vocab = build_vocab_map(VALID_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 128)          5504      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 256)          394240    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100, 44)           11308     \n",
      "=================================================================\n",
      "Total params: 411,052\n",
      "Trainable params: 411,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "sample_len = 100\n",
    "batch_size = 64\n",
    "hidden_dim = 256\n",
    "embedding_dim = 128\n",
    "num_lstms = 1\n",
    "max_vocab_index = len(vocab)\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model = build_lstm_model(sample_len, num_lstms, hidden_dim, embedding_dim, vocab)\n",
    "print(max_vocab_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000 200000 44\n",
      "(' have an empathy deficit when were still sending our children down corridors of shame, schools in th', 'have an empathy deficit when were still sending our children down corridors of shame, schools in the')\n",
      "('those of us who manage the publics dollars will be held to account -- to spend wisely, reform bad ha', 'hose of us who manage the publics dollars will be held to account -- to spend wisely, reform bad hab')\n",
      "('or every american family that is paying the price at the pump -- we must end this dependence on fore', 'r every american family that is paying the price at the pump -- we must end this dependence on forei')\n",
      "(' and reduce premiums for medicare beneficiaries by roughly 43 billion over the next 10 years. and im', 'and reduce premiums for medicare beneficiaries by roughly 43 billion over the next 10 years. and im ')\n",
      "('ree suspected terrorists. let me repeat that three convictions in over seven years. instead of bring', 'ee suspected terrorists. let me repeat that three convictions in over seven years. instead of bringi')\n",
      "('l qaeda attack, it is just as likely, if not more, that it will be here in europe in a european city', ' qaeda attack, it is just as likely, if not more, that it will be here in europe in a european city.')\n",
      "('nt to move in the same direction towards a better future for our children and our grandchildren. and', 't to move in the same direction towards a better future for our children and our grandchildren. and ')\n",
      "(' will likely be made up of 35-50,000 u.s. troops. through this period of transition, we will carry o', 'will likely be made up of 35-50,000 u.s. troops. through this period of transition, we will carry ou')\n",
      "('ing intrinsically wrong in us taking better care of ourselves. but what accounts for the bulk of our', 'ng intrinsically wrong in us taking better care of ourselves. but what accounts for the bulk of our ')\n",
      "('he way for europes renaissance and enlightenment. it was innovation in muslim communities -- it was ', 'e way for europes renaissance and enlightenment. it was innovation in muslim communities -- it was i')\n"
     ]
    }
   ],
   "source": [
    "print(len(norm_text_train), len(norm_text_val), len(vocab))\n",
    "testgen=sample_text(norm_text_train, sample_len, vocab)\n",
    "for _ in range(10):\n",
    "    print(next(testgen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "12500/12500 [==============================] - 1181s 95ms/step - loss: 1.3117 - acc: 0.6024 - val_loss: 1.2638 - val_acc: 0.6162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84d4de6470>"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit_generator(generator=sample_text(norm_text, 40),\n",
    "#                    validation_data=None,\n",
    "#                    use_multiprocessing=True,\n",
    "#                    workers=6)\n",
    "\n",
    "model.fit_generator(generator=sample_batch(norm_text_train, sample_len, batch_size, vocab), \n",
    "                    steps_per_epoch=int(len(norm_text_train)/batch_size),\n",
    "                    validation_data=sample_batch(norm_text_val, sample_len, batch_size, vocab, shuffle=False),\n",
    "                    validation_steps=int(len(norm_text_val)/batch_size),\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'americans and the recovery plan that will be the democratic contrality that we should be a new tradition of a conflict of the world with the moment when we are not a served that it was the future of the co'"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = normalize_text(\"ameri\", VALID_CHARS, REPLACE_CHARS)\n",
    "generate_text(model, txt, vocab, inv_vocab, sample_len, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n"
     ]
    }
   ],
   "source": [
    "text = \"abcdefgh\"\n",
    "samp = \"xyz\"\n",
    "generator1 = sample_text(text, 5)\n",
    "generator2 = sample_batch(text, 5, 3, vocab)\n",
    "for i in range(10):\n",
    "    samp = next(generator2)\n",
    "    print(samp[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-cd4dfaf6f66e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuild_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-124-cae222c7f544>\u001b[0m in \u001b[0;36mbuild_lstm_model\u001b[0;34m(max_text_len, lstm_hidden_dim)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_hidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_hidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_2: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s and they are many.', ' and they are many. ')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator1 = sample_text(norm_text, 20)\n",
    "next(generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
